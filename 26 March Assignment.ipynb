{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "009784a3",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7cd788",
   "metadata": {},
   "source": [
    "Ans1. Simple linear regression is a statistical method used to establish a linear relationship between two variables, with one variable acting as the independent variable, and the other as the dependent variable. Multiple linear regression, on the other hand, involves finding a linear relationship between a dependent variable and two or more independent variables.\n",
    "\n",
    "Example of simple linear regression: Examining the relationship between the hours spent studying and the grade obtained in a test. Here, the number of hours spent studying is the independent variable, and the grade obtained is the dependent variable.\n",
    "\n",
    "Example of multiple linear regression: Examining the relationship between the sales of a product, advertising expenditure, and price. Here, sales is the dependent variable, and advertising expenditure and price are the independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac19cff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b655804f",
   "metadata": {},
   "source": [
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5afc1b2",
   "metadata": {},
   "source": [
    "Ans2. The assumptions of linear regression include linearity, homoscedasticity, independence of errors, normality of errors, and absence of multicollinearity.\n",
    "\n",
    "To check whether these assumptions hold in a given dataset, we can create diagnostic plots such as residual plots, fitted vs residuals plot, normal probability plot, and leverage plot. We can also perform statistical tests such as the Shapiro-Wilk test to test for normality and the Breusch-Pagan test to test for homoscedasticity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6573f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a37b9a60",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05282f00",
   "metadata": {},
   "source": [
    "Ans3. The slope and intercept in a linear regression model represent the relationship between the dependent and independent variables. The intercept represents the value of the dependent variable when the independent variable is zero, while the slope represents the change in the dependent variable for every one unit change in the independent variable.\n",
    "\n",
    "Example: A linear regression model examining the relationship between the number of years of education and annual income can be written as Y = a + bX, where Y represents annual income, X represents the number of years of education, a represents the intercept, and b represents the slope. In this scenario, the intercept represents the income of an individual with zero years of education, while the slope represents the increase in income for every one additional year of education."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9520dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00c5b348",
   "metadata": {},
   "source": [
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc24f16",
   "metadata": {},
   "source": [
    "Ans4. Gradient descent is an optimization algorithm used in machine learning to minimize the loss function. The loss function measures the difference between the predicted and actual values of the dependent variable. Gradient descent iteratively adjusts the parameters of the model to minimize the loss function by computing the gradient of the loss function with respect to the model parameters and adjusting the parameters in the direction of the negative gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e886c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1b9135d",
   "metadata": {},
   "source": [
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a30f04",
   "metadata": {},
   "source": [
    "Ans5. The multiple linear regression model is a statistical method used to establish a linear relationship between a dependent variable and two or more independent variables. The model can be represented as Y = a + b1X1 + b2X2 + ... + bnXn, where Y represents the dependent variable, X1, X2, ... Xn represent the independent variables, a represents the intercept, and b1, b2, ..., bn represent the slopes.\n",
    "\n",
    "The model differs from simple linear regression, which involves finding a linear relationship between a dependent variable and a single independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecce6346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "354139db",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e508326b",
   "metadata": {},
   "source": [
    "Ans6. Multicollinearity is a phenomenon in multiple linear regression, where two or more independent variables are highly correlated, making it difficult to determine the individual effects of each variable on the dependent variable. Multicollinearity can lead to unstable and unreliable coefficient estimates.\n",
    "\n",
    "To detect multicollinearity, we can calculate the correlation matrix between the independent variables or perform variance inflation factor (VIF) analysis. To address multicollinearity, we can remove one of the correlated variables or combine the variables into a composite variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbc68a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6554f004",
   "metadata": {},
   "source": [
    "Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5e1efe",
   "metadata": {},
   "source": [
    "Ans7. Polynomial regression is a form of regression analysis in which the relationship between the independent variable (x) and the dependent variable (y) is modeled as an nth degree polynomial. Unlike linear regression, which models a linear relationship between x and y, polynomial regression can capture more complex, nonlinear relationships between the variables.\n",
    "\n",
    "Polynomial regression involves fitting a curve to the data that minimizes the sum of the squared differences between the observed and predicted values of the dependent variable. The curve can be of any degree, with higher degree polynomials allowing for more complex relationships to be captured.\n",
    "\n",
    "In essence, polynomial regression is an extension of linear regression, allowing for more flexibility in modeling nonlinear relationships between the variables. However, it also introduces the possibility of overfitting the data, as the model may capture noise in the data and not generalize well to new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759a4beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "290aea16",
   "metadata": {},
   "source": [
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d25e48",
   "metadata": {},
   "source": [
    "Ans8. Advantages of polynomial regression over linear regression include:\n",
    "* Flexibility: Polynomial regression allows for more complex relationships between the dependent and independent variables to be modeled, capturing nonlinear relationships that linear regression cannot.\n",
    "* Improved accuracy: When the relationship between the dependent and independent variables is nonlinear, polynomial regression can provide a better fit to the data and improve the accuracy of predictions.\n",
    "* Capturing interactions: Polynomial regression can also capture interactions between independent variables that are missed by linear regression.\n",
    "\n",
    "Disadvantages of polynomial regression compared to linear regression include:\n",
    "* Overfitting: As the degree of the polynomial increases, the model can become more complex and overfit the data, capturing noise rather than the true underlying relationship.\n",
    "* Interpretability: Polynomial regression models can be more difficult to interpret and explain than linear regression models.\n",
    "* Extrapolation: Extrapolating beyond the range of the data can be more challenging with polynomial regression than with linear regression, as the model may not accurately capture the true underlying relationship outside of the range of the data.\n",
    "\n",
    "In general, polynomial regression is preferred over linear regression when there is evidence of a nonlinear relationship between the dependent and independent variables. However, caution should be exercised in selecting the degree of the polynomial to prevent overfitting. It is also important to evaluate the model using appropriate metrics and cross-validation techniques to ensure that it generalizes well to new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be8d088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
