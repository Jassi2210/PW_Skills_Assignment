{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c0ad470",
   "metadata": {},
   "source": [
    "## Q1. What is the difference between Ordinal Encoding and Label Encoding? Provide an example of when you might choose one over the other.\n",
    "## Ans1. Both Ordinal Encoding and Label Encoding are techniques used for encoding categorical data into numerical data. However, they differ in how they assign numerical values to categories.\n",
    "\n",
    "## Ordinal Encoding assigns a unique integer value to each category based on its rank or order. For example, if we have a dataset with categorical feature \"size\" having categories 'S', 'M', and 'L', then we can assign them integer values 1, 2, and 3, respectively, based on their order. Ordinal encoding is useful when the categories have a natural ordering, such as sizes or ratings.\n",
    "\n",
    "## Label Encoding, on the other hand, assigns a unique integer value to each category without considering their order or rank. For example, if we have a dataset with categorical feature \"color\" having categories 'red', 'blue', and 'green', we can assign them integer values 0, 1, and 2, respectively, without considering any specific order or rank. Label encoding is useful when the categories do not have a natural ordering.\n",
    "\n",
    "## In summary, Ordinal Encoding is used when the categories have a natural order, while Label Encoding is used when the categories do not have a natural order.\n",
    "\n",
    "## Example: Suppose we have a dataset containing a feature called \"education level\" with categories 'high school', 'college', and 'graduate school'. Here, the categories have a natural order, and hence we can use Ordinal Encoding to assign integer values 1, 2, and 3 to the categories based on their order. However, if we have a feature called \"favorite color\" with categories 'red', 'blue', and 'green', we cannot assign any natural order to the categories, and hence we can use Label Encoding to assign integer values 0, 1, and 2 to the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94a6ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bff49b0",
   "metadata": {},
   "source": [
    "## Q2. Explain how Target Guided Ordinal Encoding works and provide an example of when you might use it in a machine learning project.\n",
    "## Ans2- Target Guided Ordinal Encoding is a technique used to encode categorical features where the categories are assigned an ordinal value based on their relationship with the target variable. The idea behind this encoding is to convert the categorical variable into a numerical variable that is correlated with the target variable.\n",
    "\n",
    "## The steps involved in Target Guided Ordinal Encoding are:\n",
    "\n",
    "## 1.Group the categories in the categorical variable by their frequency or mean of the target variable.\n",
    "## 2.Order the categories based on the frequency or mean.\n",
    "## 3.Assign a rank to each category.\n",
    "## 4.Replace the categorical values with the assigned rank.\n",
    "## For example, suppose we have a dataset that contains information about customers of a bank, including their age, income, and credit score. The target variable is whether or not the customer defaulted on a loan. We want to encode the categorical variable 'education,' which has the categories 'high school,' 'college,' and 'graduate.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d6cd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "053c8a5f",
   "metadata": {},
   "source": [
    "## Q3. Define covariance and explain why it is important in statistical analysis. How is covariance calculated?\n",
    "## Ans3- Covariance is a measure of how two variables change with respect to each other. It measures the degree to which two variables are linearly related to each other. In statistical analysis, covariance is important because it helps to identify the relationship between two variables. Specifically, a positive covariance indicates that the variables tend to move in the same direction, while a negative covariance indicates that the variables tend to move in opposite directions.\n",
    "\n",
    "## The covariance between two variables X and Y can be calculated using the following formula:\n",
    "\n",
    "## cov(X,Y) = E[(X - E[X]) * (Y - E[Y])]\n",
    "\n",
    "## ## where E[X] and E[Y] are the expected values (means) of X and Y, respectively.\n",
    "\n",
    "## If the covariance between two variables is zero, then the variables are said to be uncorrelated. However, it is important to note that zero covariance does not necessarily imply independence between the variables. Additionally, the magnitude of the covariance is not standardized and can be affected by the scales of the variables. Therefore, it is often useful to calculate the correlation coefficient, which is a standardized measure of covariance that ranges from -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89849ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed1ff401",
   "metadata": {},
   "source": [
    "## Q4. For a dataset with the following categorical variables: Color (red, green, blue), Size (small, medium, large), and Material (wood, metal, plastic), perform label encoding using Python's scikit-learn library. Show your code and explain the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12920772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color  Size  Material\n",
      "0      2     2         2\n",
      "1      0     1         0\n",
      "2      1     0         1\n",
      "3      2     1         2\n",
      "4      0     2         0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# create a sample dataset\n",
    "data = {'Color': ['red', 'blue', 'green', 'red', 'blue'],\n",
    "        'Size': ['small', 'medium', 'large', 'medium', 'small'],\n",
    "        'Material': ['wood', 'metal', 'plastic', 'wood', 'metal']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# perform label encoding on all columns\n",
    "df_encoded = df.apply(le.fit_transform)\n",
    "\n",
    "# print encoded dataset\n",
    "print(df_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77482cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6a7c2a8",
   "metadata": {},
   "source": [
    "## Q5. Calculate the covariance matrix for the following variables in a dataset: Age, Income, and Education level. Interpret the results.\n",
    "## Ans5-As the variables are numerical, we will assume a continuous variable to calculate the covariance matrix. Let's assume that we have a dataset with n observations of these variables:\n",
    "\n",
    "## Age: [a1, a2, a3, ..., an]\n",
    "\n",
    "## Income: [i1, i2, i3, ..., in]\n",
    "\n",
    "## Education level: [e1, e2, e3, ..., en]\n",
    "\n",
    "## The formula to calculate the covariance between two variables x and y is:\n",
    "\n",
    "## cov(x,y) = sum((xi - mean(x)) * (yi - mean(y))) / (n-1)\n",
    "\n",
    "## Using this formula, we can calculate the covariance between each pair of variables:\n",
    "\n",
    "## cov(Age, Income) = sum((ai - mean(Age)) * (ii - mean(Income))) / (n-1)\n",
    "\n",
    "## cov(Age, Education level) = sum((ai - mean(Age)) * (ei - mean(Education level))) / (n-1)\n",
    "\n",
    "## cov(Income, Education level) = sum((ii - mean(Income)) * (ei - mean(Education level))) / (n-1)\n",
    "\n",
    "## We can represent these results in a matrix form:\n",
    "\n",
    "## | cov(Age, Age) | cov(Age, Income) | cov(Age, Education level) |\n",
    "## | cov(Income, Age) | cov(Income, Income) | cov(Income, Education level) |\n",
    "## | cov(Education level, Age) | cov(Education level, Income) | cov(Education level, Education level) |\n",
    "\n",
    "## Interpreting the results of the covariance matrix:\n",
    "\n",
    "## The diagonal values represent the covariance of each variable with itself, which is the variance of that variable.\n",
    "## The off-diagonal values represent the covariance between pairs of variables.\n",
    "## A positive covariance indicates that the variables tend to increase or decrease together. A negative covariance indicates that the variables tend to have an opposite relationship.\n",
    "## The magnitude of the covariance is not standardized, which makes it difficult to compare covariances between different pairs of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a59779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "882c180b",
   "metadata": {},
   "source": [
    "## Q6. You are working on a machine learning project with a dataset containing several categorical variables, including \"Gender\" (Male/Female), \"Education Level\" (High School/Bachelor's/Master's/PhD), and \"Employment Status\" (Unemployed/Part-Time/Full-Time). Which encoding method would you use for each variable, and why?\n",
    "## Ans6- For the given categorical variables in the machine learning project, I would suggest the following encoding methods:\n",
    "\n",
    "## \"Gender\": Label Encoding or Binary Encoding can be used as there are only two categories (Male/Female). Label Encoding would assign 0 or 1 to each category while Binary Encoding would create two separate columns with 0 or 1 values.\n",
    "## ## \"Education Level\": Ordinal Encoding can be used as there is a clear order among the categories (High School < Bachelor's < Master's < PhD). Target Guided Ordinal Encoding can also be used if we want to encode the categories based on their relation to the target variable.\n",
    "## \"Employment Status\": One-Hot Encoding can be used as there is no inherent order among the categories. One-Hot Encoding would create separate columns for each category with 0 or 1 values.\n",
    "## The choice of encoding method would depend on the nature of the data and the specific requirements of the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853b61bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5ec0879",
   "metadata": {},
   "source": [
    "## Q7. You are analyzing a dataset with two continuous variables, \"Temperature\" and \"Humidity\", and two categorical variables, \"Weather Condition\" (Sunny/Cloudy/Rainy) and \"Wind Direction\" (North/South/ East/West). Calculate the covariance between each pair of variables and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3bf2932",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot perform reduce with flexible type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7288\\1473075065.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# calculate the covariance matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mcov_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontinuous_vars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# print the covariance matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcov\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mcov\u001b[1;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[0;32m   2516\u001b[0m             \u001b[0mw\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0maweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2518\u001b[1;33m     \u001b[0mavg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturned\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2519\u001b[0m     \u001b[0mw_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw_sum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36maverage\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36maverage\u001b[1;34m(a, axis, weights, returned)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[0mavg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m         \u001b[0mscl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mavg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         ret = um.true_divide(\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot perform reduce with flexible type"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create a dataset with Temperature, Humidity, Weather Condition, and Wind Direction\n",
    "dataset = np.array([\n",
    "    [25, 60, \"Sunny\", \"North\"],\n",
    "    [30, 50, \"Cloudy\", \"South\"],\n",
    "    [20, 70, \"Rainy\", \"East\"],\n",
    "    [28, 55, \"Sunny\", \"West\"],\n",
    "    [26, 65, \"Cloudy\", \"North\"],\n",
    "    [22, 75, \"Rainy\", \"South\"],\n",
    "    [27, 62, \"Sunny\", \"East\"],\n",
    "    [29, 58, \"Cloudy\", \"West\"]\n",
    "])\n",
    "\n",
    "# extract the continuous variables\n",
    "continuous_vars = dataset[:, :2]\n",
    "\n",
    "# calculate the covariance matrix\n",
    "cov_matrix = np.cov(continuous_vars.T)\n",
    "\n",
    "# print the covariance matrix\n",
    "print(cov_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebe3c45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
